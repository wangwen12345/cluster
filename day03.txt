一、部署HA集群：使用keepalived软件
keepalived可以解决任意单故障节点的高可用。
  keepalived运行原理
---------> 检测每个服务器的节点状态
---------->服务器节点异常或工作出现故障,Keepalived将故障节点从集群中剔除,恢复后再将其加入到集群系统中
---------->所有工作自动完成,无需人工干预

配置网站高可用集群：要求
当网站服务器192.168.4.55 宕机后，
客户端自动访问网站服务器192.168.4.57


1  在主机55 和 57 运行网站服务并编写网页文件 index.html
55主机的的页面内容 : echo  web55  >  /var/www/html/index.html
57主机的的页面内容 : echo  web57  >  /var/www/html/index.html

2 配置HA集群：
2.1 在集群主机上分别安装keepalvied软件
yum -y install keepalived.x86_64 
2.2 分别修改服务的主配置文件
主55: vim /etc/keepalived/keepalived.conf
global_defs {
  notification_email {
    admin@tarena.com.cn                     //设置报警收件人邮箱
  }
  notification_email_from ka@localhost      //设置发件人
  smtp_server 127.0.0.1                     //定义邮件服务器
  smtp_connect_timeout 30
  router_id  mysql55                        //设置路由ID号（实验需要修改）
}
vrrp_instance webha {                   1//设置集群名称
  state MASTER                          //主服务器为MASTER（实验需要修改）
  interface eth0                        //定义网络接口（实验需要修改）
  virtual_router_id 51                  //主辅VRID号必须一致（实验需要修改）
  priority 150                         2//服务器优先级,优先级高优先获取VIP（实验需要修改）
  advert_int 1
  authentication {
    auth_type PASS
    auth_pass 123456                       3//主辅服务器密码必须一致(默认1111)
  }
  virtual_ipaddress { 192.168.4.252  }     4//谁是主服务器谁获得该VIP（实验需要修改）
}
备57
1 ! Configuration File for keepalived
  2 
  3 global_defs {
  4    notification_email {
  5      acassen@firewall.loc
  6      failover@firewall.loc
  7      sysadmin@firewall.loc
  8    }
  9    notification_email_from Alexandre.Cassen@firewall.loc
 10    smtp_server 192.168.200.1
 11    smtp_connect_timeout 30
 12    router_id LVS_DEVEL
 13    vrrp_skip_check_adv_addr
 14  #  vrrp_strict                         5 //需要注销掉,否则ping不通VIP
 15    vrrp_garp_interval 0
 16    vrrp_gna_interval 0
 17 }
 18 
 19 vrrp_instance webha {                      1
 20     state BACKUP                           2
 21     interface eth0
 22     virtual_router_id 51
 23     priority 100
 24     advert_int 1
 25     authentication {
 26         auth_type PASS
 27         auth_pass 123456                   3
 28     }
 29     virtual_ipaddress {
 30       192.168.4.252                                    4 
 33     }
 34 }
2.3 分别启动主备服务器上 keepalvied服务
55:   systemctl start keepalived
57:   systemctl start keepalived

2.4 查看vip地址
ip addr show |grep 252
2.5 客户端测试： 连接vip访问服务
50: crul http://192.168.4.252/test.html


+++++++++++++++++++++++++++++++++++
配置LVS调度器高可用集群
1、 host54:
ifdown eth0
ifup  eth0
ifconfig  eth0:1
ifconfig  eth0
ipvsadm -C
ipvsadm-save  >   /etc/sysconfig/ipvsadm
安装keepalived 软件包
2、准备,备用的lvs调度器192.168.4.56 
并 安装 lvs和keepalived服务软件包
3、分别修改 56 和  54 主机的keepalived服务的配置文件
54 :  vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   router_id LVS_DEVEL
   vrrp_skip_check_adv_addr
#   vrrp_strict
   vrrp_garp_interval 0
   vrrp_gna_interval 0
}

vrrp_instance lvsha {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 150
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        192.168.4.253
    }
}
virtual_server 192.168.4.253 80 {   //设置ipvsadm的VIP规则          1
    delay_loop 6
    lb_algo rr                      //设置LVS调度算法为rr         2
    lb_kind DR                      //设置LVS的模式为DR           3
   # persistence_timeout 50                                     4
    protocol TCP

    real_server 192.168.4.52 80 {     //设置后端web服务器真是IP     5
        weight 1                      //设置权重为1   
TCP_CHECK {
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }

        }
    real_server 192.168.4.53 80 {                                6
        weight 1
TCP_CHECK {                           //健康检查
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }

        }
}


4、分别启动 56 和  54 主机的keepalived服务
5 客户端访问vip地址 ，访问网站服务
curl   http://192.168.4.253/test.html


+++++++++++++++++++++++++++++++++++
二、部署LB集群：使用Haproxy软件实现
访问56分发给55和57
HAPeoxy工作模式
mode http   客户端请求被深度分析后在发往服务器
mode tcp    客户端与服务器之间建立会话,不检查第七层信息
mode health 仅做健康状态检查,已经不建议使用

HTTP事务模型
---->http协议是事务驱动的
-------->每个请求仅能对应一个相应
-------->常见模型:
-HTTP close
-Keep-alive
-Pipelining

2.1 准备2台网站服务器  55 和 57 
2.2 配置haproxy服务56
2.2.1  装包
yum -y install haproxy

2.2.2 修改配置文件
cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak //备份配置文件防止改错
vim /etc/haproxy/haproxy.conf
组成部分
default：为后续的其他部分设置缺省参数，缺省参数可以被后续部分重置；
frontend：描述集群接收客户端请求的信息集合；
backend：描述转发链接的后端服务器集合；
listen：把frontend和backend结合到一起的完整声明。

global
 log 127.0.0.1 local2   ###[err warning info debug]
 chroot /usr/local/haproxy
 pidfile /var/run/haproxy.pid ###haproxy的pid存放路径
 maxconn 4000     ###最大连接数，默认4000
 user haproxy
 group haproxy
 daemon       ###创建1个进程进入deamon模式运行
defaults
 mode http    ###默认的模式mode { tcp|http|health } log global   ###采用全局定义的日志
 option dontlognull  ###不记录健康检查的日志信息
 option httpclose  ###每次请求完毕后主动关闭http通道
 option httplog   ###日志类别http日志格式
 option forwardfor  ###后端服务器可以从Http Header中获得客户端ip
 option redispatch  ###serverid服务器挂掉后强制定向到其他健康服务器
 timeout connect 10000 #如果backend没有指定，默认为10s
 timeout client 300000 ###客户端连接超时
 timeout server 300000 ###服务器连接超时
 maxconn  60000  ###最大连接数
 retries  3   ###3次连接失败就认为服务不可用，也可以通过后面设置
listen stats
    bind 0.0.0.0:1080   #监听端口
    stats refresh 30s   #统计页面自动刷新时间
    stats uri /stats   #统计页面url
    stats realm Haproxy Manager #统计页面密码框上提示文本
    stats auth admin:admin  #统计页面用户名和密码设置
  #stats hide-version   #隐藏统计页面上HAProxy的版本信息
stats uri /admin
listen  weblb 192.168.4.56:80
   cookie  SERVERID rewrite
   balance roundrobin
   server  web1 192.168.4.55:80 cookie app1inst1 check inter 2000 rise 2 fall 5
   server  web2 192.168.4.57:80 cookie app1inst2 check inter 2000 rise 2 fall 5

2.2.3 启动服务
systemctl restart  haproxy
systemctl enable   haproxy
2.2.4 客户端访问haproxy 服务
firefox 192.168.4.56/admin

++++++++++++++++++++++++++++
LB
Nginx
LVS
Haproxy


HTTP Keep-alive事务模型的特点是什么？
一次连接可以传输多个请求；
客户端需要知道传输内容的长度，以避免无限期的等待传输结束；
降低两个HTTP事务间的延迟；
需要相对较少的服务器资源。


7应用层  Nginx   Haproxy
6表示层
5会话层                              
4传输层 LVS    ipvasadm  -A  -t  x.x.x.x:80   -s rr
3网络层
2数据链路层
1物理层
